{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8375b282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Dropout,experimental\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2012856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"train\"\n",
    "test_path=\"test\"\n",
    "val_path=\"validate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f529e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    \n",
    "    x_train=[]\n",
    "    x_test=[]\n",
    "    x_val=[]\n",
    "    \n",
    "    for folder in os.listdir(train_path):\n",
    "\n",
    "        sub_path=train_path+\"/\"+folder\n",
    "\n",
    "        for img in os.listdir(sub_path):\n",
    "\n",
    "            image_path=sub_path+\"/\"+img\n",
    "\n",
    "            img_arr=cv2.imread(image_path)\n",
    "\n",
    "            img_arr=cv2.resize(img_arr,(224,224))\n",
    "\n",
    "            x_train.append(img_arr)\n",
    "\n",
    "\n",
    "    for folder in os.listdir(test_path):\n",
    "\n",
    "        sub_path=test_path+\"/\"+folder\n",
    "\n",
    "        for img in os.listdir(sub_path):\n",
    "\n",
    "            image_path=sub_path+\"/\"+img\n",
    "\n",
    "            img_arr=cv2.imread(image_path)\n",
    "            \n",
    "            img_arr=cv2.resize(img_arr,(224,224))\n",
    "\n",
    "            x_test.append(img_arr)\n",
    "\n",
    "    for folder in os.listdir(val_path):\n",
    "\n",
    "        sub_path=val_path+\"/\"+folder\n",
    "\n",
    "        for img in os.listdir(sub_path):\n",
    "\n",
    "            image_path=sub_path+\"/\"+img\n",
    "\n",
    "            img_arr=cv2.imread(image_path)\n",
    "\n",
    "            img_arr=cv2.resize(img_arr,(224,224))\n",
    "\n",
    "            x_val.append(img_arr)\n",
    "            \n",
    "            \n",
    "    return x_train, x_test, x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be00ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Lable \n",
    "\n",
    "def generateLable():\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    \n",
    "    training_set = train_datagen.flow_from_directory(\"train\",\n",
    "                                                     \n",
    "                                                     batch_size = 50,\n",
    "                                                     class_mode = 'sparse')\n",
    "    test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                                target_size = (224, 224),\n",
    "                                                batch_size = 50,\n",
    "                                                class_mode = 'sparse')\n",
    "    val_set = val_datagen.flow_from_directory(val_path,\n",
    "                                                \n",
    "                                                batch_size = 50,\n",
    "                                                class_mode = 'sparse')\n",
    "    return training_set.classes, test_set.classes, val_set.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aafb2197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 299 images belonging to 2 classes.\n",
      "Found 83 images belonging to 2 classes.\n",
      "Found 87 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, x_val = loadData()\n",
    "train_y, test_y, val_y = generateLable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a87bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d3edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "def augment(image, label):\n",
    "    img = tf.cast(image, tf.float32)\n",
    "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = (img / 255.0)\n",
    "    img = tf.image.random_crop(img, size=[IMG_SIZE, IMG_SIZE, 3])\n",
    "    img = tf.image.random_brightness(img, max_delta=0.5)\n",
    "    return img, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8432285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "augmented_images = list(map(augment,x_train,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81dd8f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in augmented_images:\n",
    "    x_train.append(image[0])\n",
    "    train_y = np.append(train_y,image[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2acc981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=np.array(x_train)\n",
    "test_x=np.array(x_test)\n",
    "val_x=np.array(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2524d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0\n",
    "val_x=val_x/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04089485",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7aec5279",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3a8bc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37693a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19/19 [==============================] - 30s 2s/step - loss: 0.9295 - accuracy: 0.5786 - val_loss: 0.5482 - val_accuracy: 0.7701\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 25s 1s/step - loss: 0.6654 - accuracy: 0.5819 - val_loss: 0.4427 - val_accuracy: 0.8391\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 23s 1s/step - loss: 0.6393 - accuracy: 0.6171 - val_loss: 0.3140 - val_accuracy: 0.8621\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 25s 1s/step - loss: 0.6287 - accuracy: 0.5953 - val_loss: 0.4017 - val_accuracy: 0.8276\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 24s 1s/step - loss: 0.6005 - accuracy: 0.6555 - val_loss: 0.4666 - val_accuracy: 0.8161\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 25s 1s/step - loss: 0.5728 - accuracy: 0.6672 - val_loss: 0.4226 - val_accuracy: 0.8851\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 23s 1s/step - loss: 0.4549 - accuracy: 0.7559 - val_loss: 0.1662 - val_accuracy: 0.8966\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 26s 1s/step - loss: 0.4596 - accuracy: 0.7575 - val_loss: 0.2200 - val_accuracy: 0.9310\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 25s 1s/step - loss: 0.4121 - accuracy: 0.7742 - val_loss: 0.1484 - val_accuracy: 0.9195\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 23s 1s/step - loss: 0.3608 - accuracy: 0.7809 - val_loss: 0.1359 - val_accuracy: 0.9540\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=5)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit( train_x,\n",
    "  train_y,\n",
    "  validation_data=(val_x,val_y),\n",
    "  epochs=10,\n",
    "  callbacks=[early_stop],\n",
    "  batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c4923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a661451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 205ms/step - loss: 0.2988 - accuracy: 0.9036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2988491654396057, 0.9036144614219666]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9d93ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a442d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = [np.argmax(elements) for elements in predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaba67d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 1 1\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "print(*ans)\n",
    "print(*test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b124f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d1172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
